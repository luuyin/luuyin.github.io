---
---

@string{aps = {American Physical Society,}}


@article{yin2021hierarchical,
abbr={AAAI (Workshop)},
abstract={Few-shot classification tasks aim to classify images in query sets based on only a few labeled examples in support sets.  Most studies usually assume that each image in a task has a single and unique class association. Under these assumptions, these algorithms may not be able to identify the proper class assignment when there is no exact matching between support and query classes.  For example, given a few images of lions, bikes, and apples to classify a tiger.  However, in a more general setting, we could consider the higher-level concept, the large carnivores, to match the tiger to the lion for semantic classification.  Existing studies rarely considered this situation due to the incompatibility of label-based supervision with complex conception relationships.  In this work,  we advance the few-shot learning towards this more challenging scenario, the semantic-based few-shot learning, and propose a method to address the paradigm by capturing the inner semantic relationships using interactive psychometric learning. The experiment results on the CIFAR-100 dataset show the superiority of our method for the semantic-based few-shot learning compared to the baseline.},
  title={Semantic-Based Few-Shot Learning by Interactive Psychometric Testing},
  author={<b>Yin, Lu</b> and Menkovski, Vlado and Yulong Pei and Pechenizkiy, Mykola},
  journal={AAAI 2022 Workshop on Interactive Machine Learning (IML@AAAI22)},
  year={2021},
  html={https://arxiv.org/abs/2112.09201},
  pdf={Semantic-Based Few-Shot Learning by Interactive Psychometric Testing.pdf},

}



@article{yin2021hierarchical,
abbr={ACML (Long Oral)},
abstract={Assigning meaning to parts of image data is the goal of semantic image segmentation. Machine learning methods, specifically supervised learning is commonly used in a variety of tasks formulated as semantic segmentation. One of the major challenges in the supervised learning approaches is expressing and collecting the rich knowledge that experts have with respect to the meaning present in the image data. Towards this, typically a fixed set of labels is specified and experts are tasked with annotating the pixels, patches or segments in the images with the given labels. In general, however, the set of classes does not fully capture the rich semantic information present in the images. For example, in medical imaging such as histology images, the different parts of cells could be grouped and sub-grouped based on the expertise of the pathologist. To achieve such a precise semantic representation of the concepts in the image, we need access to the full depth of knowledge of the annotator. In this work, we develop a novel approach to collect segmentation annotations from experts based on psychometric testing. Our method consists of the psychometric testing procedure, active query selection,  query enhancement, and a deep metric learning model to achieve a patch-level image embedding that allows for semantic segmentation of images. We show the merits of our method with evaluation on the synthetically generated image, aerial image and histology image.},
  title={Hierarchical Semantic Segmentation using Psychometric Learning},
  author={<b>Yin, Lu</b> and Menkovski, Vlado and Liu, Shiwei and Pechenizkiy, Mykola},
  journal={Proceedings of Machine Learning Research},
  year={2021},
  html={https://proceedings.mlr.press/v157/yin21a/yin21a.pdf},
  pdf={Hierarchical Semantic Segmentation using Psychometric Learnin.pdf}

}



@inproceedings{yin2021beyond,
abbr={IJCAI (DC)},
  title={Beyond labels: knowledge elicitation using deep metric learning and psychometric testing},
  author={<b>Yin, Lu</b>},
  booktitle={Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence},
  pages={5214--5215},
  year={2021},
  html={https://www.ijcai.org/proceedings/2020/0747.pdf},
}



@inproceedings{yin2020knowledge,
  abbr={ECML},
  abstract={Knowledge present in a domain is well expressed as relationships between corresponding concepts. For example, in zoology, animal species form complex hierarchies; in genomics, the different (parts of) molecules are organized in groups and subgroups based on their functions; plants, molecules, and astronomical objects all form complex taxonomies. Nevertheless, when applying supervised machine learning (ML) in such domains, we commonly reduce the complex and rich knowledge to a fixed set of labels, and induce a model shows good generalization performance with respect to these labels. The main reason for such a reductionist approach is the difficulty in eliciting the domain knowledge from the experts. Developing a label structure with sufficient fidelity and providing comprehensive multi-label annotation can be exceedingly labor-intensive in many real-world applications. In this paper, we provide a method for efficient hierarchical knowledge elicitation (HKE) from experts working with high-dimensional data such as images or videos. Our method is based on psychometric testing and active deep metric learning. The developed models embed the high-dimensional data in a metric space where distances are semantically meaningful, and the data can be organized in a hierarchical structure. We provide empirical evidence with a series of experiments on a synthetically generated dataset of simple shapes, and Cifar 10 and Fashion-MNIST benchmarks that our method is indeed successful in uncovering hierarchical structures.},
  title={Knowledge Elicitation Using Deep Metric Learning and Psychometric Testing},
  author={<b>Yin, Lu</b> and Menkovski, Vlado and Pechenizkiy, Mykola},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={154--169},
  year={2020},
  organization={Springer},
  selected={true},
  html={https://arxiv.org/pdf/2004.06353.pdf},
  pdf={Knowledge Elicitation using Deep Metric Learning and Psychometric Testing.pdf},
}


